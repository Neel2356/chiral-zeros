{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6df34bc3-c47d-4d98-96a3-a4fa77b893ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from biopandas.pdb import PandasPdb\n",
    "import pandas as pd\n",
    "import random\n",
    "import itertools\n",
    "import copy\n",
    "import scipy\n",
    "import math\n",
    "import sys\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy.spatial.distance import directed_hausdorff, pdist, squareform, cdist\n",
    "from scipy.spatial import KDTree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial.transform import Rotation as R\n",
    "from scipy.spatial.distance import directed_hausdorff, cdist\n",
    "from scipy.optimize import minimize\n",
    "from itertools import product\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "072caa32-215f-43ec-a887-9244b8c244a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_haus(degs, L, D):\n",
    "    \n",
    "    x,y,z,a,b,c = degs   \n",
    "    \n",
    "    r = R.from_euler('xyz', [a,b,c])\n",
    "    D = r.apply(D)\n",
    "    \n",
    "    D += [x,y,z]\n",
    "    haus, _, _ = directed_hausdorff(L, D)\n",
    "    \n",
    "    return haus\n",
    "\n",
    "def haus_opt(x0, L, D):\n",
    "\n",
    "    res = minimize(min_haus, x0, method='SLSQP', args=(L,D), options={'ftol': 1e-3, 'disp': False})\n",
    "\n",
    "    return res['fun'], res['x']\n",
    "\n",
    "def hcm(L):\n",
    "    D = -L\n",
    "    perm = product(np.linspace(-np.pi, np.pi, 10), repeat=3) #from -pi to pi rads, 24 even groups in between them \n",
    "    inits_abc = np.array([i for i in perm])\n",
    "    # iter_xyz = product(np.linspace(-np.max(cdist(c1_xyz, c1_xyz)) /50, np.max(cdist(c1_xyz, c1_xyz)) /50, 3), repeat=3)\n",
    "    # inits_xyz = np.array([i for i in iter_xyz])\n",
    "    inits_xyz = np.zeros([1,3])\n",
    "    inits = np.append(np.tile(inits_xyz, [len(inits_abc), 1]), np.repeat(inits_abc, len(inits_xyz), axis=0), axis=1)\n",
    "\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    output = Parallel(n_jobs=num_cores)(delayed(haus_opt)(i, L, D) for i in inits)\n",
    "    values = [_[0] for _ in output]\n",
    "    return (min(values) / np.max(cdist(L,L)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00d8ca29-2bc9-4806-8ebf-ebea70ffde96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CA_coord(pdb_name, chain1, chain2):\n",
    "\n",
    "    coord1 = PandasPdb()\n",
    "    coord1.fetch_pdb(pdb_name)\n",
    "    # coord1.read_pdb(os.path.join(protein_dir, pdb_name + '.pdb'))\n",
    "    prot1_df = coord1.df['ATOM']\n",
    "    prot1_df = prot1_df[(prot1_df['alt_loc'] == \"\") | (prot1_df['alt_loc'] == \"A\")]\n",
    "    \n",
    "    c1_ = [[] for _ in range(len(chain1))]\n",
    "    for ii in range(len(chain1)):\n",
    "        c1_[ii] = prot1_df[prot1_df['chain_id'] == chain1[ii]]\n",
    "    c1 = pd.concat(c1_).reset_index(drop=True)\n",
    "    \n",
    "    c1_all_res = c1[['chain_id', 'residue_number', 'insertion']].drop_duplicates().reset_index(drop=True)\n",
    "    c1_ca_res = c1[c1['atom_name'] == 'CA'][['chain_id', 'residue_number', 'insertion']]\n",
    "    c1_no_cas = pd.merge(c1_all_res, c1_ca_res, how='left', indicator=True)['_merge']=='left_only'\n",
    "    \n",
    "    if sum(c1_no_cas) != 0:\n",
    "        c1_incomplete_res = np.squeeze(np.where(c1[['chain_id', 'residue_number', 'insertion']].astype(str).agg('_'.join, axis=1).to_numpy() ==\n",
    "               \t\t\t\t        c1_all_res[c1_no_cas].astype(str).agg('_'.join, axis=1).to_numpy()))\n",
    "        c1 = c1.drop(np.atleast_1d((c1_incomplete_res))).reset_index(drop=True)\n",
    "    else:\n",
    "        c1_incomplete_res = np.array([])\n",
    "    \n",
    "    c2_ = [[] for _ in range(len(chain2))]\n",
    "    for ii in range(len(chain2)):\n",
    "        c2_[ii] = prot1_df[prot1_df['chain_id'] == chain2[ii]]\n",
    "    c2 = pd.concat(c2_).reset_index(drop=True)\n",
    "\n",
    "    c2_all_res = c2[['chain_id', 'residue_number', 'insertion']].drop_duplicates().reset_index(drop=True)\n",
    "    c2_ca_res = c2[c2['atom_name'] == 'CA'][['chain_id', 'residue_number', 'insertion']]\n",
    "    c2_no_cas = pd.merge(c2_all_res, c2_ca_res, how='left', indicator=True)['_merge'] == 'left_only'\n",
    "\n",
    "    if sum(c2_no_cas) != 0:\n",
    "        c2_incomplete_res = np.squeeze(np.where(c2[['chain_id', 'residue_number', 'insertion']].astype(str).agg('_'.join, axis=1).to_numpy() ==\n",
    "                     c2_all_res[c2_no_cas].astype(str).agg('_'.join, axis=1).to_numpy()))\n",
    "        c2 = c2.drop(np.atleast_1d((c2_incomplete_res))).reset_index(drop=True)\n",
    "    else:\n",
    "        c2_incomplete_res = np.array([])\n",
    "    \n",
    "    c1_CA = pd.concat([c1[c1['atom_name'] == 'CA']['x_coord'],\n",
    "                       c1[c1['atom_name'] == 'CA']['y_coord'],\n",
    "                       c1[c1['atom_name'] == 'CA']['z_coord']],\n",
    "                      axis=1).to_numpy()\n",
    "    c2_CA = pd.concat([c2[c2['atom_name'] == 'CA']['x_coord'],\n",
    "                       c2[c2['atom_name'] == 'CA']['y_coord'],\n",
    "                       c2[c2['atom_name'] == 'CA']['z_coord']],\n",
    "                      axis=1).to_numpy()\n",
    "\n",
    "    return c1, c2, c1_CA, c2_CA, c1_incomplete_res, c2_incomplete_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38766482-18d8-41d4-b51a-d858c650e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_radius(A, p, r):\n",
    "    dists = cdist(A,p.reshape(1,3)).reshape(-1)\n",
    "    within_cutoff = (dists <= r)\n",
    "    selection = A[within_cutoff]\n",
    "    return selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "96eefe46-898c-47df-8a2c-f2622c083696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def osipov_whole(coord):\n",
    "    n = 2\n",
    "    m = 1\n",
    "    \n",
    "    N = len(coord)\n",
    "    \n",
    "    if N >= 4:\n",
    "        P = np.array(list(itertools.permutations(np.arange(N), 4))) # Get permutations\n",
    "        \n",
    "        coords_P = coord[P]\n",
    "        r = coords_P - np.roll(coords_P, -1, axis=1)\n",
    "        r[:, 3] = -r[:, 3]\n",
    "        r_mag = np.linalg.norm(r, axis=-1)\n",
    "    \n",
    "        cross_vecs = np.cross(r[:, 0], r[:, 2])\n",
    "    \n",
    "        G_p_up = np.einsum('ij,ij->i', cross_vecs, r[:, 3]) * np.einsum('ij,ij->i', r[:, 0], r[:, 1]) * np.einsum('ij,ij->i', r[:, 1], r[:, 2])\n",
    "        G_p_down = np.power(np.prod(r_mag[:,0:3], axis=-1), n) * np.power(r_mag[:, 3], m)\n",
    "        \n",
    "        \n",
    "        G_p = (1 / 3) * np.sum(G_p_up / G_p_down)\n",
    "    \n",
    "        G_os = (24)/(N ** 4) *  G_p\n",
    "        \n",
    "    else:\n",
    "        G_os = 0\n",
    "\n",
    "    return G_os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d1ffb30-51b9-4b10-b14c-7b909f36e3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chirality_scale_matrix_hcm(c1):\n",
    "    c2 = c1[c1['atom_name'] == 'CA']\n",
    "    \n",
    "    # All non-hydrogen atoms in protein\n",
    "    chain1 = c1\n",
    "    chain1_arr = np.asarray(chain1[['atom_number', 'x_coord', 'y_coord', 'z_coord']])\n",
    "    A1 = np.asarray(chain1[['x_coord', 'y_coord', 'z_coord']])\n",
    "\n",
    "    # All carbon alphas in protein\n",
    "    chain2 = c2\n",
    "    chain2_arr = np.asarray(chain2[['atom_number', 'x_coord', 'y_coord', 'z_coord']])\n",
    "    A2 = np.asarray(chain2[['x_coord', 'y_coord', 'z_coord']])\n",
    "\n",
    "    # Compute diamater of protein\n",
    "    distances = squareform(pdist(A1))\n",
    "    diameter = distances.max()\n",
    "\n",
    "    radii = np.array([2,4,6,8,10])\n",
    "    vector_list = []\n",
    "\n",
    "    for row in A2:\n",
    "        row_vec = np.asarray([hcm(get_radius(A1, row, r)) for r in radii])\n",
    "        vector_list.append(row_vec)\n",
    "\n",
    "    result_arr = np.vstack(vector_list)\n",
    "    result_df = pd.DataFrame(result_arr)\n",
    "    result_df.columns = radii\n",
    "    result_df.index = chain2_arr[:, 0]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dc94c2a-5299-4c6c-b222-76f31bd39da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chirality_scale_matrix_opd(c1):\n",
    "    c2 = c1[c1['atom_name'] == 'CA']\n",
    "    \n",
    "    # All non-hydrogen atoms in protein\n",
    "    chain1 = c1[c1['element_symbol'] != 'H']\n",
    "    chain1_arr = np.asarray(chain1[['atom_number', 'x_coord', 'y_coord', 'z_coord']])\n",
    "    A1 = np.asarray(chain1[['x_coord', 'y_coord', 'z_coord']])\n",
    "\n",
    "    # All carbon alphas in protein\n",
    "    chain2 = c2\n",
    "    chain2_arr = np.asarray(chain2[['atom_number', 'x_coord', 'y_coord', 'z_coord']])\n",
    "    A2 = np.asarray(chain2[['x_coord', 'y_coord', 'z_coord']])\n",
    "\n",
    "    # Compute diamater of protein\n",
    "    distances = squareform(pdist(A1))\n",
    "    diameter = distances.max()\n",
    "\n",
    "    radii = np.array([3])\n",
    "    vector_list = []\n",
    "\n",
    "    for row in A2:\n",
    "        row_vec = np.asarray([osipov_whole(get_radius(A1, row, r)) for r in radii])\n",
    "        vector_list.append(row_vec)\n",
    "\n",
    "    result_arr = np.vstack(vector_list)\n",
    "    result_df = pd.DataFrame(result_arr)\n",
    "    result_df.columns = radii\n",
    "    result_df.index = chain2_arr[:, 0]\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cbf22721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_helices(pdb_name, chain):\n",
    "    helix_list = []\n",
    "    \n",
    "    ### 1. Fetch whole PDB, multiple chains\n",
    "    coord = PandasPdb()\n",
    "    coord.fetch_pdb(pdb_name)\n",
    "    p1 = coord.df['ATOM']\n",
    "    # p1_CA = p1[p1['atom_name']== 'CA']\n",
    "    \n",
    "    ### 2. Fetch single chain\n",
    "    c_id = coord.df['ATOM']['chain_id'].unique()\n",
    "    print(c_id)\n",
    "    c1 = coord.df['ATOM'][coord.df['ATOM']['chain_id']==chain]\n",
    "    # c1_CA = c1[c1['atom_name']== 'CA']\n",
    "    \n",
    "    ### 3. Fetch alpha helix from chain\n",
    "    h1 = coord.df['OTHERS'][coord.df['OTHERS']['record_name']=='HELIX']\n",
    "    h1 = h1['entry'].str.split('\\s+', expand=True)[[4,5,8,10]]\n",
    "    h1.columns = ['chain_id', 'start_res', 'end_res', 'size']\n",
    "    h1['start_res'] = h1['start_res'].astype('int')\n",
    "    h1['end_res'] = h1['end_res'].astype('int')\n",
    "    h1['size'] = h1['size'].astype('int')\n",
    "    all_helices = h1[h1['chain_id']==chain]\n",
    "    all_helices.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    ### 4. Fetch dfs from all_helices\n",
    "    for hel in range(len(all_helices)):\n",
    "        helix_list.append(c1[(c1['residue_number']>=all_helices['start_res'].iloc[hel]) & (c1['residue_number']<=all_helices['end_res'].iloc[hel])])\n",
    "        \n",
    "    return helix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81fc6e9d-e678-4e7e-b72f-f6a4cc352765",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_sheets(pdb_name, chain):\n",
    "    helix_list = []\n",
    "    \n",
    "    ### 1. Fetch whole PDB, multiple chains\n",
    "    coord = PandasPdb()\n",
    "    coord.fetch_pdb(pdb_name)\n",
    "    p1 = coord.df['ATOM']\n",
    "    # p1_CA = p1[p1['atom_name']== 'CA']\n",
    "    \n",
    "    ### 2. Fetch single chain\n",
    "    c_id = coord.df['ATOM']['chain_id'].unique()\n",
    "    print(c_id)\n",
    "    c1 = coord.df['ATOM'][coord.df['ATOM']['chain_id']==chain]\n",
    "    # c1_CA = c1[c1['atom_name']== 'CA']\n",
    "    \n",
    "    ### 3. Fetch alpha helix from chain\n",
    "    h1 = coord.df['OTHERS'][coord.df['OTHERS']['record_name']=='SHEET']\n",
    "    h1 = h1['entry'].str.split('\\s+', expand=True)[[4,5,8,10]]\n",
    "    h1.columns = ['chain_id', 'start_res', 'end_res', 'size']\n",
    "    h1['start_res'] = h1['start_res'].astype('int')\n",
    "    h1['end_res'] = h1['end_res'].astype('int')\n",
    "    h1['size'] = h1['size'].astype('int')\n",
    "    all_helices = h1[h1['chain_id']==chain]\n",
    "    all_helices.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    ### 4. Fetch dfs from all_helices\n",
    "    for hel in range(len(all_helices)):\n",
    "        helix_list.append(c1[(c1['residue_number']>=all_helices['start_res'].iloc[hel]) & (c1['residue_number']<=all_helices['end_res'].iloc[hel])])\n",
    "        \n",
    "    return helix_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2da1df36-82b7-4864-8db6-c3a47e325634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdb_name = \"1IGT\"\n",
    "# chain = \"A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "54390b1e-b3bc-4c50-a08e-8946425fb49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helix_list = []\n",
    "    \n",
    "# ### 1. Fetch whole PDB, multiple chains\n",
    "# coord = PandasPdb()\n",
    "# coord.fetch_pdb(pdb_name)\n",
    "# p1 = coord.df['ATOM']\n",
    "# # p1_CA = p1[p1['atom_name']== 'CA']\n",
    "    \n",
    "# ### 2. Fetch single chain\n",
    "# c_id = coord.df['ATOM']['chain_id'].unique()\n",
    "# print(c_id)\n",
    "# c1 = coord.df['ATOM'][coord.df['ATOM']['chain_id']==chain]\n",
    "# # c1_CA = c1[c1['atom_name']== 'CA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5c48cc0-9be0-4bd8-934b-a75599d257f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 3. Fetch alpha helix from chain\n",
    "# h1 = coord.df['OTHERS'][coord.df['OTHERS']['record_name']=='SHEET']\n",
    "# h1 = h1['entry'].str.split('\\s+', expand=True)[[4,5,8,10]]\n",
    "# h1.columns = ['chain_id', 'start_res', 'end_res', 'size']\n",
    "# h1['start_res'] = h1['start_res'].astype('int')\n",
    "# # h1['end_res'] = h1['end_res'].astype('int')\n",
    "# # h1['size'] = h1['size'].astype('int')\n",
    "# # all_helices = h1[h1['chain_id']==chain]\n",
    "# # all_helices.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "# # ### 4. Fetch dfs from all_helices\n",
    "# # for hel in range(len(all_helices)):\n",
    "# #     helix_list.append(c1[(c1['residue_number']>=all_helices['start_res'].iloc[hel]) & (c1['residue_number']<=all_helices['end_res'].iloc[hel])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3b86a446-8978-41b7-9858-bedde6aadbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your CSV file with escaped backslashes\n",
    "file_path = \"/home/nmoudgal/OPD_Project/DB5.csv\"\n",
    "\n",
    "# Load the CSV file into a NumPy array\n",
    "data = np.asarray(pd.read_csv(file_path, delimiter=','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0a41cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A' 'B' 'C' 'D' 'E']\n",
      "['E' 'I']\n",
      "success\n",
      "success\n",
      "['A' 'B' 'C' 'D' 'E' 'F']\n",
      "['A' 'B' 'C' 'D']\n",
      "success\n",
      "success\n",
      "success\n",
      "['A' 'B' 'C' 'D' 'E']\n",
      "['A' 'D']\n",
      "error\n",
      "['A' 'B']\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "['A' 'B']\n",
      "success\n",
      "success\n",
      "['A' 'B' 'C']\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'H']\n",
      "success\n",
      "success\n",
      "success\n",
      "['R' 'S']\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "success\n",
      "Saved!\n",
      "['A' 'B']\n",
      "success\n",
      "success\n"
     ]
    }
   ],
   "source": [
    "results_1 = []  # List to store length, hcm, and opd values for the first interacting partner\n",
    "\n",
    "for i in range(len(data)):\n",
    "    pdb_name = data[i][0]\n",
    "    chain1 = data[i][1]\n",
    "    \n",
    "    try:\n",
    "        array = fetch_helices(pdb_name, chain1)\n",
    "        for j in range(len(array)):\n",
    "            coords = array[j]\n",
    "            coords1 = coords[coords[\"atom_name\"] == \"CA\"]\n",
    "            coords1 = coords1.loc[:, [\"x_coord\", \"y_coord\", \"z_coord\"]].to_numpy()\n",
    "            coords = coords.loc[:, [\"x_coord\", \"y_coord\", \"z_coord\"]].to_numpy()\n",
    "            hcm_value = hcm(coords)\n",
    "            osipov_value = osipov_whole(coords)\n",
    "            length = len(coords1)\n",
    "            results_1.append([length, hcm_value, osipov_value])  \n",
    "            print(\"success\")\n",
    "    except:\n",
    "        print(\"error\")\n",
    "    if i % 10 == 0 and i > 0:\n",
    "        results_1_df = pd.DataFrame(results_1, columns=[\"Length\", \"HCM\", \"OPD\"])\n",
    "        results_1_df.to_csv(\"helix_chir_new.csv\", index=False)\n",
    "        print(\"Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580c0f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results, columns=[\"HCM\", \"Osipov Whole\"])        \n",
    "results_df.to_csv(\"results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55406e85-a88f-49c5-b0c9-be149d936384",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = results[:, 0]  # First column\n",
    "y = results[:, 1]  # Second column\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x, y, s=10, alpha=0.8)  # Adjust `s` and `alpha` for point size and transparency\n",
    "plt.title(\"HCM vs. OPD for Naturally Occurring Alpha Helices\", fontsize=16)\n",
    "plt.xlabel(\"HCM\", fontsize=14)\n",
    "plt.ylabel(\"OPD\", fontsize=14)\n",
    "m, b = np.polyfit(x, y, 1)  # Linear fit (degree 1)\n",
    "\n",
    "# Plot the line of best fit\n",
    "plt.plot(x, m * x + b, color=\"red\", label=\"Best Fit Line\", linewidth=2)\n",
    "\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013c42cd-416d-40cb-ae16-b8ece3d9eadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.array(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aea8143-0d44-47db-b9cf-ea83ec532b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = results[:, 0]  # First column\n",
    "y = np.abs(results[:, 1])  # Second column\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(x, y, s=10, alpha=0.8)  # Adjust `s` and `alpha` for point size and transparency\n",
    "plt.title(\"HCM vs. OPD for Naturally Occurring Alpha Helices\", fontsize=16)\n",
    "plt.xlabel(\"HCM\", fontsize=14)\n",
    "plt.ylabel(\"Absolute OPD\", fontsize=14)\n",
    "m, b = np.polyfit(x, y, 1)  # Linear fit (degree 1)\n",
    "\n",
    "# Plot the line of best fit\n",
    "plt.plot(x, m * x + b, color=\"red\", label=\"Best Fit Line\", linewidth=2)\n",
    "\n",
    "\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da568bec-3281-4886-a0c7-9020c43ffb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.corrcoef(x, y)[0, 1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcm",
   "language": "python",
   "name": "hcm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
